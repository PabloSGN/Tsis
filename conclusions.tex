\chapter{Conclusions}

In this manuscript we have provided a thorough overview of the entire process required to achieve scientific solar observations and subsequent data analysis. This journey begins with the design and calibration of TuMag, the tunable magnetograph aboard the Sunrise III observatory. Continues with its operation during the 2024 observation campaign and it showcasing its data reduction-showing the preliminary results of the data processing. Then, we highlighted some of the challenges that arise during the redution of FPI-based spectrometers with a special interest on the cavity map correction in telecentric setups. And lastly it concludes with an example of scientific data exploitation, employing the persistent homology technique to study solar magnetograms.

The fundamental pilar that holds a significant amount of the work of this thesis is the 2024 observation campaign for the third iteration of Sunrise and the preparation for it. All subsystems performed nearly flawlessly throughout the six-day campaign, delivering several terabytes of high-quality data to reduce and analyze. While processing this data will likely take months, we have aimed to offer an initial look at TuMag’s output and demonstrate the potential of its observations.

From TuMag's perspective, the campaign yielded six terabytes of data combining science observations and calibrations. Although the pipeline is still in development and lacks some of the neccesary steps to achieve science-ready data, the data-reduction process started the moment we got access to the data and the preliminary results shown in chapter \ref{CH:Pipeline} are proof of the exceptional performance of the instrument. TuMag's spectral, optical and polartimetric performances are as expected. The first image reconstructions have shown that we are able to deconvolve the PSF and enhance the spatial resolution for all datasets that have been analyzed. Spectrally, TuMag does not show any abnormal behaviour. The main challenge being the correction of the pre-filter and the removal of the second-order contamination, which is a correction that we plan to tackle soon. Regarding the polarimetric performance, the results show that we are able to derive the Stokes components with a sensistivity fulfilling the requirements. Nonetheless, a thorough analysis of the micropolarizers and linar polarizer observations is pending to accurately asses and correct the presence cross-talk.

Overall, TuMag’s data is highly promising. With its high-resolution data comprising various targets, spectral lines, and strong polarimetric sensitivity, combined with the data from SCIP and SUSI, Sunrise holds the potential for groundbreaking solar science. 

The need for months to properly prepare the raw data for scientific use originates from the fact that many corrections require careful, manual application and cannot be fully automated without a thorough initial assessment. In order to provide a better understanding of this topic, in chapter \ref{CH:challenges} we have explored the challenges that arise in the data reduction of FPI-based spectrometers, specifically those employing telecentric setups. Equipped with the analytical modelling of the FPIs, we have been able to address the impact of the etalon defects on the observations. We have quantified the error commited in the computations of LOS velocities and magentic fields when the cavity errors are (only) partially corrected through the simulation of an observation of a Sunspot. Additionally, we have provided a new strategy for the data correction of etalon-based spectrometers that separates the effects of the FPIs on the flat-fields from other effects in an attempt to improve the flat-field correction. Lastly, we have tested the performance of this new method on a series of simulated observations and real data to verify its applicability. 

The simulation of the sunspot observation in section \ref{sect: Mancha_obs} demonstrates the significant impact of improperly corrected cavity errors on the physical measurements. The discussion is centered around the flat-fielding procedure, which presents one of the main challenges in these setups, as cavity errors also affect flat-field observations. We show that these flat-fields alter and distort the observed spectral profiles when applied. The correlation between the structures found in the velocity calculation errors after flat-field correction and those of the cavity map suggests that the flat-fielding has not (fully) corrected these errors. In the penumbra, errors can reach up to 400 ms$^{-1}$ for both flat-fielding approaches, which would invalidate any measurements, as penumbral flows are of similar magnitudes.

Furthermore, we found that the shape of the transmission profile affects the measurements, with velocities derived using an asymmetrical transmission profile differing from those obtained with a symmetrical one. This, combined with the distinct behavior of the umbra compared to the rest of the field of view (FoV), implies that these measurements are sensitive to both the shape of the transmission profile and the spectral profile of the object.

Similar effects are observed in the magnetic field calculations, where the error structures correspond to those of the cavity map. However, in the case of magnetic fields, this effect is less significant, as the error values are small relative to the observed values (3 G of error in a 100 G field).

These results motivate the pursuit of methods to account for and correct these effects. One such method is the algorithm we developed to disentangle the FPI-based spurious effects on the flat-fields from those of other origins. The method, presented in Section \ref{sect: etalon_corr_fitting}, is capable of extracting the cavity map from the observations by employing the analytical modeling of the FPIs in different configurations.

We evaluated the performance of the algorithm through a series of simulated tests designed to assess various key aspects of its applicability to real data. In the first place, the performance of the algorithm was tested as a function of the S/N of the observations, the spectral sampling, and the configuration of the etalon, assuming the spectrum of the object is known. We also studied the possibility of deriving the observed object from the data through a deconvolution process. We tested the performance of this approach as a function of the spectral sampling. Finally, we simulated a scenario in which the etalon configuration was different from the real one. The aim of these tests was to assess the impact of neglecting some properties of the etalon, such as the asymmetries in telecentric imperfect scenarios.

The algorithm has shown a high sensitivity to the noise level of the data. Nonetheless, the worst-case scenario considered in this work corresponds to much worse performances than current instruments can achieve in terms of S/N, and the errors are still within the necessary limits. In addition, the performance of the algorithm is the same for regions of the FoV where the etalon properties are far from their nominal values and regions where there is no deviation of the etalon properties. 

Results for the three different optical configurations of the etalon are very similar. The telecentric configuration showed a worse performance than the collimated one in terms of cavity map retrieval. The loss of precision is nonetheless very small, below $\sim 5$~ms$^{-1}$ in most cases. 

The deconvolution of the object during the calculations was shown to yield a performance close to the ideal case in terms of cavity map determination. The performance when computing the gain showed a different behavior, although the average error never exceeds 0.4\%. Concerning the dependence on the spectral sampling, the results show that with a scanning of at least six points, the additional error of deconvolving the object will not be larger than 25~ms$^{-1}$. Overall, we estimated a total error smaller than 100~ms$^{-1}$ for the worst-case scenario, where only five wavelengths are used to scan the line using the deconvolution approach for an S/N of 200.

In real instruments, light travels through different optical elements before reaching the etalon. Along this light path, the observed object might be modified in such a way that it no longer resembles a fixed reference. It is in fact very difficult to assess the error associated with this assumption (i.e., assuming that the object reaching the etalon is that of the FTS atlas profile) since these deviations cannot be measured. By deriving the object from the data, we expect additional errors due to the deconvolution process of around 10~ms$^{-1}$, which we expect to be smaller than the ones produced by selecting a fixed object that differs considerably from the real one. Additionally, the deconvolution of the object allowed us to apply the algorithm to data where a solar structure is partly present.

Knowledge of the exact shape of the transmission profile has proven to be relevant to ensuring the accuracy of the algorithm. The results obtained for the crossover scenario have demonstrated that approximating the FPI's transmission profile by another can serve as a first-order approximation. However, the determination of the gain has proven to be much more sensitive to changes in the transmission profile. The errors observed in the crossover scenario are higher overall than those of the ideal case. In addition, the unaccounted asymmetries of the imperfect configuration paradoxically increase the error when improving the spectral sampling.

The results obtained when applying the algorithm to real observations taken with SO/PHI reinforce the validity of the algorithm. Indeed, we have been able to extract the contribution of the cavity map from the flat-field observations. Comparison of the derived cavity map with lab measurements suggests that the algorithm can successfully extract the cavity map from the flat-field observations. In future works, we aim to allow the algorithm to modify the angle of incidence across the FoV and validate the results by implementing them in the SO/PHI pipeline.

Only after the data has been meticulously reduced and all instrumental effects are removed can the observations be reliably used for scientific purposes. We aimed at providing a brief example of such a study with already reduced spectropolarimetric data in chapter \ref{CH:Science}. In this chapter, we present a study where we investigate the most adequate approach for the application of persistent homology algorithms to the analysis of solar magnetograms. By combining different filtrations in a single one-dimensional persistent homology analysis, we can effectively capture structures corresponding to both polarities of the magnetic field. We have applied this analysis to observations of the quiet Sun and active regions, taken with both Hinode/SOT and SDO/HMI, respectively. Lastly, we have analyzed the results and identified the features of the data that can be found through persistent diagrams and images, and also show some examples of applications of the algorithms. 

Our proposed approach to persistent homology algorithms involves the integration of sublevel and superlevel filtrations within a single analysis, enabling the creation of a comprehensive persistence diagram that encompasses features from both positive and negative magnetic structures. Through the examination of the positions of these identified features within the resulting persistence diagram, we can discern the diverse magnetic features present in the magnetograms. This approach has demonstrated its efficacy in capturing the intricate complexity of magnetic structures, with a particular emphasis on active regions. Through this method, we have achieved successful differentiation between the various morphologies present in active regions by analyzing the presence or absence of specific features in the corresponding persistence images. 

On the other hand, the persistent images obtained from quiet Sun observations exhibit significant similarity to each other. This indicates a lack of overall evolution in the magnetic structures within these regions. In quiet Sun areas, small regions of magnetic flux interact with each other in small-scale events, while the overall structure remains relatively static. These small-scale events become more apparent in persistent images when the field of view is reduced. These small-scale events, such as flux emergence or cancellation, can be observed through persistent images as a joint movement of negative and positive features. In cancellation events, the features move toward the center of the image, while in emergence events, they move away from the center.

Additionally, we have successfully identified interactions between opposite-polarity magnetic fields by detecting ring-like features formed by these two polarities. To achieve this, we introduced a method for calculating an `interaction diagram' that selectively displays features resulting from the interaction between polarities. This interaction diagram is generated by comparing the ring-like features identified in an analysis using only the absolute value of the signal with those found in the standard analysis. This approach enables us to detect the presence of $\delta$-spots and quantify the level of interaction between polarities, which is one of the critical factors for the understanding and prediction of flare eruptions. 

In conclusion, our application of persistent homology to solar magnetograms has provided a comprehensive and insightful framework for studying magnetic structures on the solar surface. The topological features derived from magnetograms serve as a foundation for classifying active regions based on their morphology and level of interaction, as certain topological features may have inherent connections to solar atmospheric phenomena. For instance, the presence of interaction rings in active regions might be correlated with flare production, while the interaction of signals from opposite polarities observed in a persistent diagram in the quiet Sun could be linked to small-scale reconnection events or the separation of signals associated with flux emergence. The exploration of these relationships and the assessment of the presented tools in achieving precise active region classification and their potential as predictive tools are topics of our upcoming research. Moreover, we have introduced new tools, such as the interaction diagram, which facilitates the detection and quantification of structures interacting with opposite polarities, like $\delta$-spots, addressing a crucial aspect of flare prediction. The findings presented in this article lay a solid foundation for future studies, emphasizing the potential of persistence images as valuable inputs for machine learning algorithms and contributing to advancements in space weather forecasting.

Lastly, it is important to emphasize that in this study we have focused primarily on static images in order to provide a solid basis for future investigations. The next logical step in this study is to complete the analysis of active regions, which includes examining their temporal evolution. This approach allows for the simultaneous consideration of two key factors in understanding flare eruption processes: morphological complexity, whose analysis is intrinsic to persistent homology, and the study of their temporal evolution through the analysis of the evolution of persistence and interaction diagrams.
