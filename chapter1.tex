\chapter{Introduction}

\section{Background}

In June 2009, the first Sunrise observatory \citep{SunriseI} was launched from Kiruna, Sweden, aboard a stratospheric ballon. Equipped with a 1-m aperture telescope, a multi-wavelength UV filter imager, and IMaX, a Fabry-Pérot-based magnetograph, Sunrise was the most complex payload carried by a solar stratospheric balloon to date. Aimed at studying the magnetic fields of the Sun and the dynamics of solar plasma convective flows, the mission was an outstanding success. It resulted in the publication of over a hundred peer-reviewed scientific articles in numerous high-impact journals, including Astronomy and Astrophysics (A\&A), The Astrophysical Journal (APJ), and Solar Physics, among others.

Following the success of its inaugural flight, Sunrise embarked on a second journey \citep{SunriseII} on June 13, 2013. The primary objective of this subsequent flight was to investigate the active regions of the Sun, as it remained completely \textit{quiet} throughout the entirety of the initial flight. Despite minimal alterations to the instrumentation aboard the observatory, the variance in solar activity during this second flight yielded fresh perspectives and valuable data, ultimately securing the mission success, despite encountering some technical challenges.

Given the success of the first two flights, a third iteration of the Sunrise mission was planned, featuring an updated design. For this third edition, the telescope was equipped with three post-focal instruments: SUSI, a UV spectrograph; SCIP, an infrared spectrograph; and TuMag, the evolution of the IMaX magnetograph. Sunrise III was initially scheduled to fly during the summer of 2020 but was postponed to 2022.

The third launch of Sunrise plays a crucial role in this dissertation. This thesis, initiated in 2020, was centered on the development of the data reduction pipeline for the TuMag instrument, which was entirely developed by the Spanish solar physics consortium. According to the original plan, the first half of the thesis was dedicated to the calibration of the instrument and the preparation of the data pipeline. This way, once the mission was launched, the second half of the thesis could focus on the correction and scientific analysis of the data produced during this third flight. However, this plan (and thus the scope of the thesis) encountered a setback on July 10, 2022, when the third flight of the Sunrise observatory had to be aborted just a few hours after the launch due to a mechanical failure during the ascent phase.

The observatory was recovered days later after a brief stay in the Scandinavian Alps. Both the telescope and the instruments were found to be in good condition, allowing for the recovery of the observatory and providing hope for a second attempt. However, the process of retrieving the instruments, disassembling, calibrating, and verifying their condition before relaunching the mission is lengthy, and it was not until this year, 2024, that a second attempt became feasible.

In the absence of data produced by Sunrise to process, analyze, and exploit, the scientific work conducted within the framework of this thesis has been compelled to slightly shift its focus. Over these years, we have focused on delving deeper into image correction techniques for data obtained from Fabry-Pérot interferometers, such as TuMag and IMaX. As well as conducting several studies using data products from other instruments, such as the Polarimetric and Helioseismic Imager aboard Solar Orbiter (SO/PHI) and HMI. 

\begin{figure}
  \centering
  \includegraphics[width = \textwidth]{figures/Introduction/SunriseIII_trajectory.pdf}
  \caption{Sunrise III trajectory.} 
  \label{fig_intro: sunrise_trajectory}
\end{figure}


It wasn't until the 10$^{\text{th}}$ of July of 2024 that Sunrise III got its second chance to fly, and this time, the opportunity was not wasted. After a very succesful flight that lasted 6 days, the observatory landed in the northern region of Canadá on the XX of July. Figure XX shows the trajectory our favourite solar observcatory followed over this days. The recovery process started immediately after landing, and we were able to lay hands on the data for the first time on September 2024. 

In the following chapters, we will present the work undertaken during the calibration and commissioning of TuMag, conducted in 2021, 2022, and 2024. Additionally, the research carried out between the first and second flights of Sunrise III, which has resulted in the publication of two articles as the main author — one published in APJ and the other in A\&A — will also be detailed in this manuscript, as well as other studies that have not yet been published in any scientific journal. 


\section{Motivation of our work}

In experimental sciences, there is a very strong relation between technological and scientific advances due to the simple fact that we cannot draw conclussions from what we cannot see. We believe it is important for experimental scientists, and more specifically, for observational astronomers, to know the limitations and capabilities and understand the functioning of the instruments we use. 

This philosophy is one of the pillars of this thesis, which covers topics ranging from the design and calibration of scientific instruments to the exploitation of the data they produce. With this thesis, we aim to provide a broad, yet detailed, view of the various stages of a scientific mission, from its conception and objectives through its design and calibration, data reduction and preparation for scientific exploitation, and finally, the studies and conclusions derived from it.

In particular, we will detail this process within the framework of solar physics through the development of TuMag, the magnetograph aboard Sunrise III. We will present the scientific objectives of the mission and attempt to link the design concepts with the scientific questions we aim to answerr. We will address the challenges encountered in data correction due to the technical or instrumental limitations, a subject of ongoing debate within the community and of current relevance. And finally, we also aim to offer a brief dip into the scientific explotation that can be carried out with the final data product. 

With this thesis we aim to clarify the following points:

\begin{itemize}
  \Myitem Scientific objectives of TuMag.
  \Myitem Instrumental ways of achieving the scientific purposes
  \Myitem Open problems for data reduction. Flat-fields, etalon effects in the data. 
  \Myitem Offering an example of data exploitation with aa study case. Persistent Homology.
\end{itemize}

\section{Introduction}

Astronomy is one of the broadest fields of knowledge. It studies everything from the smallest astronomical objects, such as the small asteroids that inhabit our solar system, to the global structure and evolution of the universe, including the study of planetary systems, stars, black holes and the galaxies in which they are found. However, despite the diversity of disciplines—ranging from stellar astronomy, radio astronomy, and cosmology, to extragalactic astronomy, astrobiology, and solar physics—they all share a common tool for studying the cosmos: light. Since the very beginning of astronomy, the astronomer's work has been to learn how to modify and measure the properties of the photons that reach us in order to infer the characteristics of the observed object. Although recent advancements have provided astronomers with new lenses to \textit{see} the cosmos, like gravitational waves (\textbf{REFERENCIA}) or neutrinos (\textbf{REFERENCIA}), among others, light remains as our main resource. Our understanding of the cosmos has always gone hand-in-hand with our ability to design and develop new (or more efficient) and clever ways to disect the light, spanning from the first solar clocks, passing through Newton's first telescope to the modern-day spaceborne telescopes like the Hubble, James Webb or Solar Orbiter. 

Solar physics is no different from other astronomical disciplines in this regard. Our main tool to \textit{see} the Sun is through light. Contrary to what one may think, solar physicists are as photon-starved as any other astronomer. Even though our star is closer and (apparently) brighter than any other astronomical object, our requirements regarding resolution and sensitivity are so high that we are as dependent on extremely optimized instrumentation as any other discipline. Thus, the development of instrumentation employing state-of-the-art technology and techniques plays an important role in modern solar physics.


\section{A brief introduction to spectropolarimeters.}

Spectropolarimeters, as suggested by the name, are devices that measure the spectral and polarimetric properties of light, or in other words, that measure the polarization state of light as a function of wavelength. Their use is widely extended in astrophysics due to the huge amout of information about the light source we can infer from these properties.

In solar physics, it is common to encounter two distinct types of spectropolarimeters, distinguished by their approach to spectroscopy: slit-based spectrographs, such as SUSI and SCIP, and narrow-band tunable filtergraphs, like TuMag. The latter preserve spatial resolution by capturing two-dimensional images of the solar scene at the expense of sacrificing spectral resolution. Conversely, slit-based spectrographs provide excellent spectral resolution but have a limited spatial resolution. 

Regardless of how spectroscopy is carried out, spectropolarimeters must be able to measure the polarization state of light. That is, they must be capable of determining the Stokes parameters  of the incident light. These four parameters, usually grouped in a pseudo-vector: $[I, Q, U, V]$, were defined by Stokes in \cite{Stokes_vector} as a mathematical formalism to completely define to polarization state of light. The first parameter, $I$, represents the total intensity; $Q$ and $U$ provide information about the intensity of linearly-polarized light, at 0º and 90º, respectively; and lastly, $V$, accounts for the intensity of circularly polarized light. 

Excellent polarimetric sensitivity and spectral resolution are wasted if the optical capabilities of the instrument are not up to par. The design of these instruments must achieve diffraction-limited imaging, with a signal-to-noise ratio ensuring a polarimetric sensitivity of 1000 (typically), and the best spatial resolution the telescope allows, all without sacrificing spectral resolution and accomplishing this in the shortest possible time.

When designing the instrument, one must balance these three properties: spectral, optical, and polarimetric capabilities, trying to improve the performance in all of them without sacrificing too much. In the following sections, we will delve into each of these aspects in more detail.

\subsection{Imaging and optical quality.\label{sec: intro-imaging}}

Filtergraphs are, first and foremost, imagers. The high-resolution imaging that filtergraph instruments are capable of is one of the pivotal reasons for their extended use. The ability to capture a two-dimensional scene of the solar surface makes them ideal for studying solar plasma structures, which require resolutions close to 100 km on the solar photosphere. These instruments must be able to ensure an image quality and resolving power enough to measure these structures. For this reason, we will begin our description of the filtergraphs with a brief explanaiton of image formation and image quality assessment. 

Let us assume that the extended source we are observing has a instensity distribution in the image plane given by $O(\xi _ 0, \eta _ 0)$. Then, if we assume a linear optical system and incoherent illumination, the intensity distribution measured at a point $\xi, \eta$ of the image is given by : 

\begin{equation}
  I_ j\left(\xi, \eta ; \lambda_{s}\right)= \iint  O\left(\xi_0, \eta_0\right)  \mathcal{S}\left(\xi_0, \eta_0; \xi , \eta;\right)  \mathrm{d} \xi_{0} \mathrm{~d} \eta_{0},
  \label{eq_imaging: intensity_simple}
\end{equation}
where $\mathcal{S}\left(\xi_0, \eta_0; \xi , \eta;\right)$ represents the imaging response of the instrument, also referred to as the Point Spread Function (PSF). The PSF describes the normalized intensity distribution in the image plane when observing a point source, which, due to diffraction and inherent imperfections in any imaging system, cannot be imaged as an ideal point.

The PSF is crucial in the assessment of image quality and resolving power of an instrument since it defines how fine detail will be imaged into the detector. One particularly relevant metric for image quality assessment that can be derived from the PSF isthe optical transfer function (OTF), which is the Fourier transform of the PSF \citep{vargas_tesis}. 

\begin{equation}
  OTF(\nu) = \mathcal{F}\left[\mathcal{S}\left(\xi_0, \eta_0; \xi , \eta;\right)\right],
\end{equation}
where the operator $\mathcal{F}$ is the Fourier transform, and $\nu$ the spatial frequencies.

The OTF describes how different spatial frequencies are transferred from the object to the image, thus characterizing the system's ability to resolve fine details. However, since imaging systems measure intensities, we are primarily concerned with how the intensity pattern of an object is transferred to the image. A key metric for quantifying this transfer is modulation, or contrast, which is defined as the ratio between the peaks and valleys of intensity at a given spatial frequency:

\begin{equation}
  M _ {\nu} = \frac{I_{max} ^{\nu} - I_{min} ^{\nu}}{I_{max} ^{\nu} + I_{min} ^{\nu}}.
\end{equation}

The function that encodes the dependency of the modulation with spatial frequencies is called the modulation transfer function (MTF), ands strictly related to the OTF as the ratio of the modulation of the object $MTF_{obj}$ and that of the image $MTF_{im} $can be computed from the magnude of the OTF \citep{OTF}:

\begin{equation}
  MTF = \frac{MTF_{im}(\nu)}{MTF_{obj}(\nu)} = | OTF(\nu) |.
\end{equation}

From this definition, it is evident that a perfect optical system would have an $MTF=1$ at all spatial frequencies, meaning that all details are perfectly transferred from the object to the image. However, real optical systems exhibit a decrease in MTF as spatial frequency increases. In practice, the resolution of an optical system can, and is often defined as the spatial frequency at which both the MTF and, consequently, the OTF reach zero \citep{wfes}. This threshold frequency marks the limit beyond which the system can no longer resolve finer details. 

Another key concept for assessing the imaging performance is the phase error or wavefront. The wavefront of an optical system is defined as the deviation in phase at any point within the image from that of an ideal spherical wavefront \citep{WFE_def}. Such deviations arise from various optical imperfections within the imaging system, and their impact on image quality depends on the specific nature of the aberration. For instance, imperfections in mirror shape or lens configuration can result in spherical aberrations, leading to a broadening of the point spread function (PSF) and a subsequent reduction in resolution. Other common aberrations include astigmatism, where the focal point varies along different axes, producing distorted images, and comatic aberrations (coma), which can occur due to misalignment of optical elements and manifest as tail-like distortions in the images of point sources.

It is common to see requirements or assessment of the optical quality in terms of the root mean square (rms) of the variance of the wavefront, $\Delta \phi (\xi, \eta)$, usually refered to as the wavefront error (rms WFE) or simply WFE:

\begin{equation}
  WFE = \sqrt{\frac{1}{A}\int _ {A} \left( \Delta \phi (\xi, \eta) \right) ^2 \mathrm{d \xi}\mathrm{d \eta}},
\end{equation}
where $A$ is the area of the aperture. 

This value, essentially the standard deviation of the wavefront across the FoV, is closely tied to beam propagation quality. In fact, it can be demonstrated that the wavefront variance can be derived from the Strehl ratio, or conversely, the Strehl ratio can be computed from the wavefront error. The Strehl ratio is defined as the ratio of the peak intensity of a point source in an aberrated system to that of an ideal system operating at the diffraction limit. It is one of the most widely used metrics for assessing the optical quality of a system, ranging from 1, for a perfect, unaberrated system, to 0. For small aberrations, the Strehl ratio (SR) and WFE are related by the following expression \citep{WFE_def}: 

\begin{equation}
  SR \simeq \exp \left[ - \left(\frac{2\pi WFE}{\lambda}\right) ^2 \right].
\end{equation}

Although the Strehl ratio and rms WFE provide a concise measure of the optical quality of a system, the WFE contains additional information that can further elucidate imaging performance. Rather than relying solely on a single averaged value (such as the standard deviation), the wavefront can be represented as a two-dimensional map projected onto a plane normal to the light path, typically the image plane. To carry out such a representation analytically, it is essential to select an appropriate mathematical framework. Given the widespread use of circular apertures in telescopes, mirrors, lenses, and other optical components, it is advantageous to approach the problem using polar coordinates, $\rho$ and $\theta$, and in particular, to employ an orthonormal basis for theinterpretability of the results. Among the multiple (infinite) sets of polynomials that fullfill these requirements, the Zernike polynimals \citep{Zernike} offer some distinct advantages. The Zernike polynomials are a sequence of polynomials that compose an orthonormal basis over a unit circle. Given an arbitrary wavefront, ($W(\rho, \theta)$), the expansion in terms of the Zernike polynomials can be expressed as:
\begin{equation}
  W(\rho, \theta) = \sum_{n, m} C _n ^m Z _ n ^m(\rho, \theta),
\end{equation}
where $Z _n ^m$ are the Zernike polinomyals, $C_n ^m$ are the amplitues of the coeffiecients in the expansion and $n$ and $m$ are the radial order and angular frequency, repectively. The Zernike polinomyals can be obtained from:

\begin{equation}
  \left.
  \begin{array}{l}
  Z _ n ^m (\rho, \theta) = R _ n ^m (\rho) \cos (m\theta)\ , \ \text{for} \ m \geqslant 0 \ ,\\
  \\
  Z _ n ^{-m} (\rho, \theta) = R _ n ^m (\rho) \sin (m\theta) \ , \ \text{for}  \ m < 0 \ ,
  \end{array}
  \right\}
\end{equation}
where $R _ n ^m (\rho)$ are the radial functions given by:
\begin{equation}
  R_n^m(\rho)=\sum_{l=0}^{(n-m) / 2} \frac{(-1)^l(n-l)!}{l!\left[\frac{1}{2}(n+m)-l\right]!\left[\frac{1}{2}(n-m)l-\right]!}\rho ^{n - 2l} \ .
\end{equation}

This representation of the wavefront is particularly valuable because each mode, defined by a specific pair of $n$ and $m$ values, corresponds to a distinct aberration in the wavefront, with the associated coefficient representing the rms WFE for that specific aberration. Furthermore, the orthogonality of the Zernike basis ensures that adding additional terms to the expansion does not influence the values of previously calculated coefficients. In other words, the Zernike polynomial expansion enables the wavefront to be expressed as the sum of individual aberrations, providing a clear decomposition of the wavefront errors.

Figure~\ref{fig_intro: zernikes} presents an example of a simulated wavefront, including a two-dimensional cross-section and the individual Zernike components of the simulation. The simulation incorporates only the first ten Zernike polynomials, corresponding to polynomials with $n \leqslant 3$, which account for aberrations such as defocus, astigmatism, coma, and trefoil, among others. For a comprehensive overview of the Zernike expansion in wavefront characterization, we direct the reader to \citet{Zernike_guide}.

\begin{figure}
  \centering
  \includegraphics[width = \textwidth]{figures/Introduction/zernikes_combined.pdf}
  \caption{Simulation of a wavefornt employing all zernikes with $n \leqslant 3$. The top left panel shows the 3-dimensional representation of the wavefront and the top riight panel shows a cut in a plane normal to the direction of travel. The bottom two rows show the shape of the individual zernike polymials included in the simulation.} 
  \label{fig_intro: zernikes}
\end{figure}

Although properties such as the PSF and WFE provide us with a lot of information to evaluate the instruments performance they are not known a priori. Instruments need to be equipped with means to measure these quantitites in order to assees the performance and correct for any defects. The strategy to follow depends on the properties of the instrument, for instance, onground instruments may be equpiided with adaptive optics technology where the wavefront is directly measured and corrected for in real time. (REFERENCIAS). However, this approach is not feasble in all instruments, such as space-born instruments, for example, thus, other methods are required. One apprach  of special relevance for this purpose is the phase diversity technique.

The phase diversity algorithm \citep{PD_original} is a method to infer the aberrations present in an optical system by obtaining, at least, two simultaneous, or quasi-simutaneous, images of the same object introducing an additional and known aberration to one of the images.  

The algorithm works by minimizing a cost function that depends on the OTF of the system which can be parametrized by the Zernike expanison \citep{pd_cost}: 

\begin{equation}
  \mathcal{L} (C) = \sum _ {k} \frac{|I_1 (u) S_2 (u, C) - I_2(u) S_1(u, C)| ^2}{|S_1(u, C)| ^2 + |S_2(u, C)| ^2} , 
\end{equation}
where k represents the pairs of aberrated (subindex 1) and unaberrated (subindex 2) images, u is the frequency vector in the Fourier domain, I stands for the intensity distributions, S for the system's OTF expressed in terms of a Zernike expansion with coeffiecients C. 

By finding the coefficients of the zernike expansion that minimize $\mathcal{L}$, we are able to characterize the wavefront and identify the aberrations present in the optical system. Thus, determining the OTF, and consequently the PSF. 

We are interested in determining the wavefront and OTF not only as a quality indicator of the instrument but also because it allows us to restore the image and remove the effects that the aberrations introduce into the image. 

The process of removing the effects of the aberrations consists on extracting the effects of the PSF into the final intensity, or in other words, we need to \textit{deconvolve} the PSF from the image. Coming back to equation \eqref{eq_imaging: intensity_simple}, we can simplify the integrals to a convolution operator in the Fourier domain assuming an spatial invariance of the PSF. In that case, the observed intensity can be expressed by:

\begin{equation}
  I(\xi, \eta) = O(\xi, \eta) * S(\xi, \eta) + \nu (\xi, \eta)
  \label{eq_imaging: conv} 
\end{equation}  
where we added a term accounting for the noise present in real meaurmeents $\nu (\xi, \eta)$. 

The determination of $O(\xi, \eta)$ is easier to compute in the fourier domain, since the convolution operator can be expressed as the product of the corresponding fourier transformation. Taking this into account and doing a simple rearrangement of equation \eqref{eq_imaging: conv}, we can determine the object through:

FILTRO OPTIMO?

RESUMEN? 


\subsection{Spectroscopy}

Narrow-band tunable spectrographs play a significant role in this thesis. They will be extensively discussed in this chapter, particularly in relation to the design and calibration of TuMag, and again in Chapters \ref{CH:Pipeline} and \ref{CH:challenges} when addressing TuMag's pipeline and the correction of data produced by these instruments. Therefore, for the sake of simplicity, we will focus exclusively on this type of spectrographs from this point onward.

\textcolor{red}{CAMBIAR ESTO}.

Fabry-Pérot Interferometers (FPIs), also known as etalons (used interchangeably), represent one of the most prevalent forms of narrow-band tunable spectrographs. Composed by a resonant optical cavity formed by two distinct optical media, these devices allow only the passage of light with wavelengths corresponding to constructive interference within the cavity. 

The transmission profile of an etalon, being produced by an interference phenomenon, is characterized by a series of narrow and periodic transmission peaks. The wavelengths at which this resonance peaks are located, their width, and their separation are determined solely by the physical properties of the etalon. In fact, it is not difficult to demonstrate \citep{franI} that a resonant cavity produces a periodic transmission profile, with maxima occurring at a wavelength $\lambda$ such that:

\textcolor{red}{REVISAR -> VÁLIDO PARA TELECENTRIC??} 

\begin{equation}
\lambda = \frac{2nd\cos \theta}{m}\ ,
\label{eq_ch2: order_sorting}
\end{equation}
where $n$ is the refractive index of the medium inside the cavity, $d$ is the distance between the mirrors, $\theta$ is the angle of incidence of the incoming light ray and m is the interferential order ($m \in \mathbb{Z} $). 

With Eq.~\eqref{eq_ch2: order_sorting} in mind, it is clear that an etalon allows for tuning the wavelengths of the transmission peaks by either changing the distance between the mirrors or by altering the refractive index. Although changing the angle of incidence also results in a wavelength shift, it introduces other issues, such as ghost images or profile broadening in telecentric configurations, among other effects. Consequently, the angle is not used for wavelength tuning.

To tune to a single wavelength (or a very narrow band around it), it is necessary to isolate one transmission peak (main order). This is typically achieved by using a pre-filter that only allows light with wavelengths near the desired measurement region to pass through. This ensures that no light reaches the etalon that could pass through it due to interference orders other than the main one (secondary orders). 

\begin{figure}
  \centering
  \includegraphics[width = \textwidth]{figures/Introduction_to_spectropolarimeters/Etalon_and_prefilter_example.pdf}
  \caption{Transmission profiles of the same etalon with varying refractive indices (n). The dashed lines represent the original transmission profile, while the solid lines indicate the portion of the transmission profile that passes through the order-sorting pre-filter (shaded purple area).} 
  \label{fig_ch2: etalon_example}
\end{figure}

Figure \ref{fig_ch2: etalon_example} shows a simulation of the spectral behavior of this optical setup. The order-sorting pre-filter is shown with a shaded purple area and the unaltered transmission profile of the etalon is shown in dahsed lines for different values of the refractive index. In solid lines, the resulting transmission profile is shown, that is, the transmission allowed through both the pre-filter and etalon at the same time. 

\subsection{Polarimetry}

\textcolor{red}{As previously noted, determining the polarization state of light requires the determination of the components of the Stokes vector. However, these parameters cannot be measured directly since we only know how to measure intensities. Since they are  Thus, measuring the polarization of light always involves multiple measurements at once. Specifically, a number equal to the number of elements to be determineed: four for the complete Stokes vector, or two, if only the circular polarization and total intensity are to be measured. This is the root of the difficulties in measuring polarization, as the need for multiple measurements makes them much more susceptible to spurious effects compared to individual measurements.} Cambiar que es un jaleo. 

Mathematically, the effect on polarization of a linear and finite system can be treated as a combination of linear transformations on the Stokes vector and, therefore, can be represented by a matrix in $\mathbb{R}^4$, known as the \textit{Mueller Matrix}. Let $\textbf{M}$ be the matrix that describes these transformations, then the polarization state that reaches the detector follows:

\begin{equation}
  \textbf{I}_{out} = \textbf{M}\textbf{I}_{in},
  \label{eq_intro:modultaion_eqs}
\end{equation}
where $\textbf{I}_{in}$ and $\textbf{I}_{out}$ are the Stokes vectors of the light that reaches the instrument, and the detector, respectively. However, since we only know how to measure intensities, the actual quantity measured by our CCD is: 

\begin{equation}
  I_{obs} = m_{00}I_{in} + m_{01}Q_{in} + m_{02}U_{in} + m_{03}V_{in} \ \ ,
\end{equation}
where $m_{0i}$ is the i-th element of the first row of the Mueller Matrix. This means that the intensity we measure is a linear combination of the different polarization states of the incoming light. To determine the values of the individual parameters $I_{in}$, $Q_{in}$, $U_{in}$, and $V_{in}$, further independent measurements are necessary, which can be achieved by modifying the Mueller matrix. In particular, it is easy to see that four independent measurements are required in order to construct a system of equations that allows us to determine the full Stokes vector. This process is known as modulation, and the four independent measurements are referred to as modulations.

If we denote each of the modulations by $I _ j$ with $j \in \left\{ 1, 2, 3, 4\right\}$, we can construct the following system of equations:

\begin{equation}
  \begin{pmatrix}
  I _ 1 \\
  I _ 2 \\
  I _ 3 \\
  I _ 4
  \end{pmatrix} = 
  \underbrace{\begin{pmatrix} 
      m ^ 1 _ {01} & m ^ 1 _ {02} & m ^ 1 _ {03} & m ^ 1 _ {04} \\ 
      m ^ 2 _ {01} & m ^ 2 _ {02} & m ^ 2 _ {03} & m ^ 2 _ {04} \\
      m ^ 3 _ {01} & m ^ 3 _ {02} & m ^ 3 _ {03} & m ^ 3 _ {04} \\
      m ^ 4 _ {01} & m ^ 4 _ {02} & m ^ 4 _ {03} & m ^ 4 _ {04} 
  \end{pmatrix}}_ {\textbf{O}}
  \begin{pmatrix}
    I _ {in} \\
    U _ {in} \\
    Q _ {in} \\
    V _ {in}
    \end{pmatrix} \, 
    \label{eq_spectro_theory: stokes_linear_comb}
\end{equation}
where the superindex in $m ^j _{oi}$ denotes the values of the Mueller Matrix for each modulation. Through straightforward algebra, it is easy to see that the stokes vector of the incoming light can be determined by $\textbf{I}_{in} = \textbf{D}\textbf{I}_{obs}$, where $\textbf{D}$ is the demodulation matrix, the inverse of the modulation matrix, $\textbf{O}$, and $\textbf{I}_{obs}$ is the vector containing the 4 measured modulations. 

Carefully determining $\textbf{O}$, and consequently $\textbf{D}$, during the instrument calibration process is crucial, as the accuracy of the determination of the Stokes components depends entirely upon it. It can be proven \citep{optimum_modulation} that the optimum modulation scheme—the values of $\textbf{D}$ that enable the Stokes vector to be computed with minimal uncertainty—satisfies the conditions:

\begin{equation}
  \varepsilon _ 1 \leqslant 1 \text{     , and     }, \sum _ {i = 2} ^4 \varepsilon _ i ^2 \leqslant 1,
  \label{eq_intro:optimum_efficiencies}
\end{equation}
where the polarimetric efficiencies for each stokes parameter (i = 1, 2, 3, 4), $\varepsilon _ i$, are defined as:
\begin{equation}
  \varepsilon _ i = \left( N_p \sum _ {j = 1} ^ {N_p} D _ {i, j} ^2\right) ^{-1/2},
  \label{eq_intro: polarimetric_efficiencies_definition}
\end{equation}
where $N_p$ is the number of independend modulations. 
When designing the modulation scheme for a given instrument, it is essential to satisfy the efficiency conditions given in Equation~\eqref{eq_intro:optimum_efficiencies} to ensure optimal polarimetric accuracy for all Stokes components. Furthermore, for equal sensitivities in the measurements of Stokes parameters Q, U, and V, the corresponding efficiencies should all be equal, with a value of $1/\sqrt{3}$. This is a very important result beacause polarimetric efficiencies are directly related to the smallest measurable polarimetric signals, the polarimetric sensitivity—essentially the inverse of the signal-to-noise ratio (SNR). This relation can be expressed as \citep{optimum_modulation}:
\begin{equation}
  \left( \frac{S}{N}\right)_i = \frac{\varepsilon _ i}{\varepsilon _ 1} \left(\frac{S}{N}\right)_1 \text{,    } i = 2, 3, 4 .
  \label{eq_intro: sn_and_efficiencies}
\end{equation}
From equations \eqref{eq_intro: sn_and_efficiencies} and \eqref{eq_intro:optimum_efficiencies} it is clear that the sensitivities for computing Stokes Q, U, and V will always be lower than that of Stokes I, as their corresponding efficiencies are smaller. To achieve an SNR of $10^3$ in Stokes measurements, which is the sensitivity required to detect weak polarization signals, an SNR of at least $ \left(S/N \right)_0 \gtrapprox 1700$ is necessary in the measurement of Stokes I for a quasi-optimal modulation scheme.

\subsection{\label{susec_spectropolarimeters: Imaging}Imaging}

\textcolor{red}{The high-resolution imaging that etalon-based instruments are capable of is one of the pivotal reasons for their extended use. The ability to capture a two-dimensional scene of the solar surface makes them ideal for studying solar plasma structures, which require resolutions close to 100 km on the solar surface. However, it is essential to achieve these resolutions while maintaining a sufficiently high signal-to-noise ratio to ensure the required polarimetric sensitivity.}

Spectropolarimeters ultimately combine measurements in polarization, spectral, and spatial (image) domains. Consequently, the final observed intensity depends on all three properties simultaneously. By integrating the spectral behavior of the etalon and pre-filter with the polatrimetric measurements, and taking into account the spatial dependence of these measurements, the observed intensity for a modulation $j$ at any point of the focal plane $\eta, \xi$ when the etalon is tuned at a wavelength $\lambda _ s$ is determined by:

\begin{equation}
  I_ j\left(\xi, \eta ; \lambda_{s}\right)=g(\xi, \eta)\int_{0}^{\infty} T(\lambda) \iint  O _ j\left(\xi_0, \eta_0 ; \lambda\right)  \mathcal{S}\left(\xi_0, \eta_0; \xi , \eta; \lambda-\lambda_{s}\right)  \mathrm{d} \xi_{0} \mathrm{~d} \eta_{0}\mathrm{d} \lambda ,
  \label{eq_spectro: General_Intensity}
\end{equation}
where $T(\lambda)$ accounts for the presence of the order-sorting pre-filter, $S\left(\xi_0, \eta_0; \xi , \eta; \lambda-\lambda_{s}\right)$ accounts for the imaging response of the instrument when tuned at the wavelength $\lambda_{s}$, $g(\xi, \eta)$ represents a spatial gain factor that accounts for any wavelength independent pixel-to-pixel intensity fluctuations ocurring in the focal plane, and $O _ j(\xi_0, \eta_ 0;\lambda)$ is the intensity distribution of the incoming light for a modulation j and is given by:
\begin{equation}
  O _ j(\xi_0, \eta_ 0;\lambda) = m_{00} ^jI_{in}(\xi_0, \eta_ 0;\lambda) + m_{01}^jQ_{in}(\xi_0, \eta_ 0;\lambda) + m_{02}^jU_{in}(\xi_0, \eta_ 0;\lambda) + m_{03}^jV_{in}(\xi_0, \eta_ 0;\lambda)
\end{equation}

Determining the imaging response of the instrument can be quite complex , as it is influenced not only by their physical characteristics but also by their optical configuration, whether collimated or telecentric. In Chapter 2, we provide a detailed overview of the properties of each configuration, their differences, and the challenges involved in using these devices for data correction.

Strehl ratio and Wfront error. 
Wilson, R. N. (2004). Reflecting Telescope Optics I: Basic Design Theory and its Historical Development. Springer.
Schroeder, D. J. (2000). Astronomical Optics. Academic Press.
Beckers, J. M. (1993). "Adaptive Optics for Astronomy: Principles, Performance, and Applications". Annual Review of Astronomy and Astrophysics, 31, 13-62.

SPEAK ABOUT PD. 

\textcolor{red}{ADD noise Discussion?}
 
\subsection{What do spectrpolarimeters tell us about the Sun?}

Spectropolarimeters are often referred to as magnetographs (\textit{e.g.}, TuMag), suggesting they measure magnetic fields directly. However, this is not entirely accurate. In astrophysics, the physical properties of the light source are inferred by correlating them with the observed properties of the light, rather than measuring them directly. By evaluating the polarization of sunlight at different wavelengths, spectropolarimeters enable us to infer the magnetic field and estimate plasma velocities on the solar surface. 

The simplest calculation we can carry out that provides us with physical quantities of the Sun is that of the line-of-sight (LOS) velocities. Given the spectral shift of a specific absorption or emission spectral line, $\Delta \lambda$, with respect to its rest position, $\lambda _ 0$ , the LOS velocities can be computed with the Doppler formula: 
\begin{equation}
  v_{LOS} = \frac{\Delta \lambda}{\lambda _ 0}c\ \ ,
  \label{eq_spectro: Doppler}
\end{equation}
where $c$ stands for the speed of light in vacuum. 

The polarization properties of light come into play when determining the magnetic fields. Due to Zeeman and Hanle effects, the polarity and spetcroscopy of spectral lines can be altered when formed in the presence of magnetic fields. Due to the Zeeman effect, the spectral lines widen or split into different polarized components when a strong magnetic field is present \citep{libro_JoseCarlos}, such as in the surroundings of sunspots and active regions. In the other hand, the Hanle effect is sensitive to weaker fields, and can be used to study, for example, the magnetic structure of solar prominences or turbulent fields in the solar photosphere \citep{hanle} where the fields are not strong enough to leave an imprint through the Zeeman effect.  

One simple strategy to employ polarization and spectral data to derive the magnetic fields is through the center-of-gravity method. According to \cite{center_of_gravity}, the LOS strength of the magnetic field can be obtained through:
\begin{equation}
  B_{LOS} = \frac{\lambda _ {+} - \lambda _ -}{2}\frac{4\pi m c}{eg_{L}\lambda_0 ^2}\ \ ,
  \label{eq_spectro: Blos-cog}
\end{equation}  
where $m$ and $e$ are the electron mass and charge respectively, $g_L$ stands for the Landé factor and $\lambda _ {+}$ and $\lambda _ {-}$ are the centroids of the right and left circularly polarized line components, respectively, and are computed by:
\begin{equation}
  \lambda _ {\pm} = \frac{\int \lambda \left[I_{cont} - (I \pm V)\right]d\lambda}{\int \left[I_{cont} - (I \pm V)\right]d\lambda} \ ,
  \label{eq_spectro: lambda_plus_minus}
\end{equation} 
where the subindex "$cont$" stands for the wavelength at the continuum. 

The vector magnetic field (\textit{i.e.}, strength, azimuth and inclination), and not only the LOS strength can also be derived. However, the derivation of these quantities has to be achieved through inversions of the radiative transfer equation (RTE). The applicability of the different methods to carry out this inversion is an extensive topic as there are some assumptions that can be applied in some cases but not in others, such as the weak-field or Milne-Eddington approximations, among others. For an extended discussion of this topic, we refer the interested reader to \cite{del2016inversion}.   